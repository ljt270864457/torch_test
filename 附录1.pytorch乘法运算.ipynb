{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a :  tensor([0.2013, 0.8408, 0.0363])\n",
      "a.size() :  torch.Size([3])\n",
      "mul_a_100 :  tensor([20.1344, 84.0774,  3.6315])\n",
      "mul_a_100.size() :  torch.Size([3])\n",
      "**************************************************\n",
      "c.size() :  torch.Size([4, 4])\n",
      "d.size() :  torch.Size([1, 4])\n",
      "mul_c_d.size() :  torch.Size([4, 4])\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.Size([2, 3])\n",
      "torch.Size([3, 4])\n",
      "torch.Size([2, 4])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 3])\n",
      "torch.Size([3])\n",
      "torch.Size([2])\n",
      "==================================================\n",
      "torch.Size([2])\n",
      "torch.Size([2])\n",
      "tensor(11)\n",
      "torch.Size([])\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "tensor(0.4844)\n",
      "torch.Size([])\n",
      "torch.Size([3, 4])\n",
      "torch.Size([4])\n",
      "tensor([-0.0192, -1.4435,  1.5825])\n",
      "torch.Size([3])\n",
      "torch.Size([10, 3, 4])\n",
      "torch.Size([4])\n",
      "torch.Size([10, 3])\n",
      "torch.Size([10, 3, 4])\n",
      "torch.Size([10, 4, 5])\n",
      "torch.Size([10, 3, 5])\n",
      "torch.Size([10, 3, 4])\n",
      "torch.Size([4, 5])\n",
      "torch.Size([10, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "# PyTorch 中的矩阵、向量、标量之间的乘法\n",
    "\n",
    "# 一、torch.mul()\n",
    "# 注意：torch.mul() 是支持广播操作\n",
    "# torch.mul(input, value, out=None)\n",
    "\n",
    "# 用标量值 value 乘以输入 input 的每个元素，并返回一个新的结果张量。 out = tensor ∗ value\n",
    "# 如果输入是FloatTensor or DoubleTensor类型，则 value 必须为实数，否则须为整数。【译注：似乎并非如此，无关输入类型，value取整数、实数皆可。】\n",
    "\n",
    "# 参数：\n",
    "# input (Tensor) – 输入张量\n",
    "# value (Number) – 乘到每个元素的数\n",
    "# out (Tensor, optional) – 输出张量\n",
    "\n",
    "import torch\n",
    "\n",
    "a = torch.randn(3)\n",
    "print(\"a : \", a)  # tensor([-1.6289,  0.2446, -0.3691])\n",
    "print(\"a.size() : \", a.size())  # torch.Size([3])\n",
    "\n",
    "mul_a_100 = torch.mul(a, 100)\n",
    "print(\"mul_a_100 : \", mul_a_100)  # tensor([-162.8945,   24.4566,  -36.9136])\n",
    "print(\"mul_a_100.size() : \", mul_a_100.size())  # torch.Size([3])\n",
    "\n",
    "print(\"*\" * 50)\n",
    "# 两个张量 input, other 按元素进行相乘，并返回到输出张量。即计算 outi = inputi ∗ otheri\n",
    "# 两计算张量形状不须匹配，但总元素数须一致。 注意：当形状不匹配时，input的形状作为输入张量的形状。\n",
    "#\n",
    "# 参数：\n",
    "#\n",
    "# input (Tensor) – 第一个相乘张量\n",
    "# other (Tensor) – 第二个相乘张量\n",
    "# out (Tensor, optional) – 结果张量\n",
    "\n",
    "c = torch.randn(4, 4)\n",
    "print(\"c.size() : \", c.size())  # torch.Size([4, 4])\n",
    "# d = torch.randn(2, 8)         # torch.Size([2, 8]) 该形状不符合广播条件\n",
    "# RuntimeError: The size of tensor a (4) must match the size of tensor b (8) at non-singleton dimension 1\n",
    "\n",
    "d = torch.randn(1, 4)  # 该形状符合广播条件\n",
    "print(\"d.size() : \", d.size())\n",
    "\n",
    "mul_c_d = torch.mul(c, d)\n",
    "print(\"mul_c_d.size() : \", mul_c_d.size())  # torch.Size([4, 4])\n",
    "\n",
    "\n",
    "# 二、torch.mm()\n",
    "# 注意，torch.mm()不支持广播（broadcast）。\n",
    "\n",
    "# torch.mm(mat1, mat2, out=None) → Tensor\n",
    "# 对矩阵mat1和mat2进行相乘。 如果mat1 是一个n×m 张量，mat2 是一个 m×p 张量，将会输出一个 n×p 张量out。\n",
    "\n",
    "print(\"^\" * 50)\n",
    "mat1 = torch.randn(2, 3)\n",
    "print(mat1.size())  # torch.Size([2, 3])\n",
    "\n",
    "# mat2 = torch.randn(1, 3)  # 该形状不支持广播\n",
    "# print(mat2.size())  # torch.Size([1, 3])\n",
    "# RuntimeError: size mismatch, m1: [2 x 3], m2: [1 x 3] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:752\n",
    "\n",
    "mat2 = torch.randn(3, 4)\n",
    "print(mat2.size())  # torch.Size([3, 4])\n",
    "\n",
    "mm = torch.mm(mat1, mat2)\n",
    "print(mm.size())  # torch.Size([2, 4])\n",
    "\n",
    "\n",
    "# 三、torch.mv()\n",
    "# 注意，torch.mv()不支持广播（broadcast）\n",
    "\n",
    "# torch.mv(mat, vec, out=None) → Tensor\n",
    "# 对矩阵mat和向量vec进行相乘。 如果mat 是一个n×m张量，vec 是一个m元 1维张量，将会输出一个n 元 1维张量。\n",
    "\n",
    "print(\"-\" * 50)\n",
    "mat = torch.randn(2, 3)\n",
    "print(mat.size())  # torch.Size([2, 3])\n",
    "\n",
    "# vec = torch.randn(2)\n",
    "# RuntimeError: size mismatch, [2 x 3], [2] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:631\n",
    "\n",
    "vec = torch.randn(3)\n",
    "print(vec.size())  # torch.Size([3])\n",
    "\n",
    "mv = torch.mv(mat, vec)\n",
    "print(mv.size())   # torch.Size([2])\n",
    "\n",
    "\n",
    "# 四、torch.dot()\n",
    "# 注意，torch.dot()不支持广播（broadcast）\n",
    "# torch.dot(tensor1, tensor2) → Tensor\n",
    "\n",
    "# 计算两个张量的点乘(内乘),两个张量都为1-D 向量\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# x = torch.tensor([2, 3, 2])  # 该形状不支持广播\n",
    "# print(x.size())  # torch.Size([3])\n",
    "# RuntimeError: inconsistent tensor size, expected tensor [3] and src [2] to have the same number of elements,\n",
    "# but got 3 and 2 elements respectively\n",
    "\n",
    "x = torch.tensor([2, 3])\n",
    "print(x.size())  # torch.Size([2])\n",
    "\n",
    "y = torch.tensor([4, 1])\n",
    "print(y.size())  # torch.Size([2])\n",
    "\n",
    "dot = torch.dot(x, y)\n",
    "print(dot)  # tensor(11)\n",
    "print(dot.size())  # torch.Size([])\n",
    "\n",
    "print(\"~\" * 50)\n",
    "\n",
    "# 五、torch.matmul()\n",
    "# 注意：torch.matmul() 支持广播\n",
    "# torch.matmul(input, other, out=None) → Tensor\n",
    "\n",
    "# 两个张量的矩阵乘积\n",
    "# 计算结果取决于张量的维度：\n",
    "# 1）如果两个张量都是 1 维，返回结果为 the dot product (scalar) 【点乘（标量）】\n",
    "\n",
    "# 2）如果两个张量都是 2 维，返回结果为  the matrix-matrix product (矩阵乘积)\n",
    "\n",
    "# 3）如果第一个参数是 1 维，第二个参数是 2 维，为了矩阵乘法的目的，在第一维上加 1（达到扩充维度的目的），\n",
    "#   矩阵计算完成之后，第一维加上的 1 将会被删掉。\n",
    "\n",
    "# 4）如果第一个参数是 2 维，第二个参数是 1 维，返回结果为 the matrix-vector product (矩阵向量乘积)\n",
    "\n",
    "# 5）如果两个参数至少是 1 维且至少一个参数为 N 维（其中N> 2），则返回 batched matrix multiply (批处理矩阵乘法)\n",
    "#   如果第一个参数是 1 维，则在其维数之前添加 1，以实现批量矩阵乘法并在计算之后删除 1。\n",
    "#   如果第二个参数是 1 维，则在其维数之前添加 1，以实现批量矩阵乘法并在计算之后删除 1。\n",
    "#   非矩阵（即批处理）尺寸被广播（因此必须是可广播的）。\n",
    "#   例如，如果 input 的张量是  j×1×n×m ，\n",
    "#            other 的张量是  k×m×p，\n",
    "#            out 的张量将会是 j×k×n×p\n",
    "\n",
    "\n",
    "# case 1：vector x vector\n",
    "tensor1 = torch.randn(3)\n",
    "print(tensor1.size())  # torch.Size([3])\n",
    "tensor2 = torch.randn(3)\n",
    "print(tensor2.size())  # torch.Size([3])\n",
    "matmul_1_2 = torch.matmul(tensor1, tensor2)\n",
    "print(matmul_1_2)  # tensor(0.2001) -- scalar\n",
    "print(matmul_1_2.size())  # torch.Size([])\n",
    "\n",
    "\n",
    "# case 4： matrix x vector (该情况下不支持广播，matrix的列数必须要和vector的行数一致才能进行计算)\n",
    "tensor3 = torch.randn(3, 4)\n",
    "print(tensor3.size())  # torch.Size([3, 4])\n",
    "tensor4 = torch.randn(4)\n",
    "print(tensor4.size())  # torch.Size([4])\n",
    "matmul_3_4 = torch.matmul(tensor3, tensor4)\n",
    "print(matmul_3_4)  # tensor([ 0.8020,  0.2547, -1.2333])\n",
    "print(matmul_3_4.size())  # torch.Size([3])\n",
    "\n",
    "\n",
    "# case 5：batched matrix x broadcasted vector\n",
    "a = torch.randn(10, 3, 4)\n",
    "print(a.size())  # torch.Size([10, 3, 4])\n",
    "b = torch.randn(4)\n",
    "print(b.size())  # torch.Size([4])\n",
    "matmul_a_b = torch.matmul(a, b)\n",
    "print(matmul_a_b.size())  # torch.Size([10, 3])\n",
    "\n",
    "# case 5：batched matrix x batched matrix\n",
    "c = torch.randn(10, 3, 4)\n",
    "print(c.size())  # torch.Size([10, 3, 4])\n",
    "d = torch.randn(10, 4, 5)\n",
    "print(d.size())  # torch.Size([10, 4, 5])\n",
    "matmul_c_d = torch.matmul(c, d)\n",
    "print(matmul_c_d.size())  # torch.Size([10, 3, 5])\n",
    "\n",
    "# case 5：batched matrix x broadcasted matrix\n",
    "m = torch.randn(10, 3, 4)\n",
    "print(m.size())  # torch.Size([10, 3, 4])\n",
    "n = torch.randn(4, 5)\n",
    "print(n.size())  # torch.Size([4, 5])\n",
    "matmul_m_n = torch.matmul(m, n)\n",
    "print(matmul_m_n.size())  # torch.Size([10, 3, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
